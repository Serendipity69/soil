{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_is_installed():\n",
    "    import pycaret\n",
    "    from pycaret import show_versions\n",
    "    show_versions()\n",
    "\n",
    "try:\n",
    "    what_is_installed()\n",
    "except:\n",
    "    !pip install prophet\n",
    "    !pip install pycaret-ts-alpha\n",
    "    what_is_installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --pre pycaret\n",
    "#%pip install tsfresh\n",
    "#%pip uninstall pycaret-ts-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMaxnibbM9nH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, grangercausalitytests\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYdCQ8DSN2T5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "#import missingno as mno \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-1M4oWvNgyv"
   },
   "outputs": [],
   "source": [
    "# Read the data into pandas DataFrames\n",
    "may = pd.read_csv(\"MeasurementMay2022.csv\")\n",
    "june = pd.read_csv(\"Measurementjune2022(1).csv\")\n",
    "july = pd.read_csv(\"MeasurementsJuly2022.csv\")\n",
    "aug = pd.read_csv(\"MeasurementAugust2022.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may = may[may['data_date']!='01/06/2022']\n",
    "june = june[june['data_date']!='01/07/2022']\n",
    "july = july[july['data_date']!='01/08/2022']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPOirIurNdRf",
    "outputId": "1e26e729-ef29-4739-fcfc-b14bfe1ed6c8"
   },
   "outputs": [],
   "source": [
    "df= pd.concat([may,june,july,aug], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['data_date'] +\" \"+ df['data_time'],\n",
    "               errors='raise',\n",
    "                   utc=\"ns\",\n",
    "                   exact=True,\n",
    "                   unit=None,\n",
    "               format=\"%d/%m/%Y %H:%M:%S\",\n",
    "                   infer_datetime_format=True,\n",
    "                   origin='unix', cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpPvm_7LODp6",
    "outputId": "c0592bb9-b1f5-4599-f7a5-f7bbbecdb2f6"
   },
   "outputs": [],
   "source": [
    "#rename columns with protacted name strings as well as the time and date column\n",
    "df= df.rename(columns= {\n",
    "                       \"Magna_6 Segment 1_ (10-30cm) Soil Moisture_%\":\"segment1(10-30cm)\",\n",
    "                       \"Magna_6 Segment 2_ (40-60 cm) Soil Moisture_%\":\"segment2(40-60cm)\",\n",
    "                       \"Magna_6 Segment 3_ (70-90 cm) Soil Moisture_%\":\"segment3(70-90cm)\",\n",
    "                       \"Magna_6 Segment 1_ (10-30 cm) Soil Electrical Conductivity_S/m\":\"segment1(EC)\",\n",
    "                       \"Magna_6 Segment 2_ (40-60 cm) Soil Electrical Conductivity__S/m\":\"segment2(EC)\",\n",
    "                        \"Magna_6 Segment 3_ (70-90 cm) Soil Electrical Conductivity__S/m\":\"segment3(EC)\"\n",
    "                       })\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig1 = go.Figure(go.Scatter(x=df.index, y=df[\"segment1(10-30cm)\"]))\n",
    "\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "sSndAtaJOb59",
    "outputId": "87d65bb5-3c6a-41c4-9a2e-2dde4ff5dcb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U16DRQZMOk12"
   },
   "outputs": [],
   "source": [
    "### !!!!! CHECK!! If removing rows from the dataseet, doesnt this create a problem in the consistency of my timeline\n",
    "## !!!!Should I instead replace it with mean of the previous readings ??????????\n",
    "\n",
    "#19/04/2022\tInstallation on site\n",
    "#22/05/2022\tProblem with moisture probe – removed and cleaned\n",
    "#22/05/2022\tpH meter removed\n",
    "#12/06/2022\tNew and old pH probe installed \n",
    "#06/07/2022\tTesting pH first try\n",
    "#27/07/2022\tTesting pH second try\n",
    "#13/08/2022\tChanged batteries – data slave\n",
    "#19/09/2022\tMade changes to pH and conductivity sensor – old/new swap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvuSV_KXOlwT"
   },
   "source": [
    "##df[df.data_date != '19/05/2022']\n",
    "## delete the above dates as required in the readme file provided\n",
    "\n",
    "df.drop(df[df['data_date'] == '19/05/2022'].index, inplace=True)\n",
    "df.drop(df[df['data_date'] == '22/05/2022'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRqbNqQbOr7l"
   },
   "outputs": [],
   "source": [
    "## replace no-data with column mean\n",
    "df['Metres above MSL'] = df['Metres above MSL'].replace(['no-data'],0.0)\n",
    "df['TOW _MH2O'] = df['TOW _MH2O'].replace(['no-data'],0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Metres above MSL']== \"no-data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-43kitJOvO7"
   },
   "outputs": [],
   "source": [
    "#convert string to float\n",
    "df['Metres above MSL'] = pd.to_numeric(df['Metres above MSL'])#.astype(float)\n",
    "df['TOW _MH2O'] = pd.to_numeric(df['TOW _MH2O'])#.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RaVSWN6Ow5I"
   },
   "outputs": [],
   "source": [
    "## check the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Temp_2']\n",
    "\n",
    "del df['Temp_1']\n",
    "\n",
    "del df['Temp_3']\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std of columns\n",
    "std_dev=df.loc['22-05-21':'22-05-23'].std().sort_values(ascending=False)\n",
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance=df.loc['22-05-21':'22-09-01'].var().sort_values(ascending=False)\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare variance from all 3 segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment1_var=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment1(10-30cm)'].var()\n",
    "segment2_var=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment2(40-60cm)'].var()\n",
    "segment3_var=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment3(70-90cm)'].var()\n",
    "print(\"segment1: \", segment1_var )\n",
    "print(\"segment2: \", segment2_var )\n",
    "print(\"segment3: \", segment3_var )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment1_std=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment1(10-30cm)'].std()\n",
    "segment2_std=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment2(40-60cm)'].std()\n",
    "segment3_std=df.loc['2022-06-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment3(70-90cm)'].std()\n",
    "print(\"segment1: \", segment1_std )\n",
    "print(\"segment2: \", segment2_std )\n",
    "print(\"segment3: \", segment3_std )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set(style=\"dark\", color_codes=True)\n",
    "#Compare the deviation for the last 4 months\n",
    "plt.figure(figsize= (12,8))\n",
    "sns.distplot(df.loc['2022-05-01 00:02:00+00:00':'2022-06-01 23:58:00+00:00']['segment1(10-30cm)'], \n",
    "            color= 'red',\n",
    "            bins = 50)\n",
    "plt.figure(figsize= (12,8))\n",
    "sns.distplot(df.loc['2022-06-01 00:02:00+00:00':'2022-07-01 23:58:00+00:00']['segment1(10-30cm)'],\n",
    "             color= 'green',\n",
    "            bins = 50)\n",
    "plt.figure(figsize= (12,8))\n",
    "sns.distplot(df.loc['2022-07-01 00:02:00+00:00':'2022-08-01 23:58:00+00:00']['segment1(10-30cm)'],\n",
    "             color= 'blue',\n",
    "            bins = 50)\n",
    "plt.figure(figsize= (12,8))\n",
    "sns.distplot(df.loc['2022-08-01 00:02:00+00:00':'2022-09-01 23:58:00+00:00']['segment1(10-30cm)'],\n",
    "             color= 'blue',\n",
    "            bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1R3NeFFO39U"
   },
   "outputs": [],
   "source": [
    "# remove the date and time column\n",
    "del df['data_date']\n",
    "\n",
    "del df['data_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nWGbgN7uO6Tz",
    "outputId": "61892875-5961-4a31-b275-1be41c0320b8"
   },
   "outputs": [],
   "source": [
    "df.plot(subplots=True, figsize=(12,65));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuQtIaRrZh48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns for segment 2 and 3\n",
    "del df['segment2(40-60cm)']\n",
    "del df['segment3(70-90cm)']\n",
    "del df['segment2(EC)']\n",
    "del df['segment3(EC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.index\n",
    "future_data = df.iloc[-7000:]\n",
    "future_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%pip install pycaret-ts-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-test set\n",
    "train = df[df.index < '2022-08-21']\n",
    "test = df[df.index >= '2022-08-21']\n",
    "# check shape\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have manually split the dataset before initializing the setup .\n",
    "An alternate would be to pass the entire dataset to PyCaret and let\n",
    "it handle the split, in which case you will have to \n",
    "pass data_split_shuffle = False in the setup function \n",
    "to avoid shuffling the dataset before the split."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import the regression module\n",
    "from pycaret.regression import *\n",
    "# initialize setup\n",
    "s = setup(data = train.reset_index(),\n",
    "          test_data = test.reset_index(),\n",
    "          target = 'segment1(10-30cm)',\n",
    "          fold_strategy = 'timeseries',\n",
    "         # numeric_features = ['date', 'Series']\n",
    "          fold = 3,\n",
    "          transform_target = True,\n",
    "          session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.time_series import TSForecastingExperiment\n",
    "\n",
    "# Change renderer appropriately based on where the notebook is being run ----\n",
    "# Refer to plotly for available renderers.\n",
    "global_plot_settings = {\"renderer\": \"colab\",\n",
    "                        \"hoverinfo\": \"text\"}\n",
    "\n",
    "\n",
    "exp = TSForecastingExperiment()\n",
    "\n",
    "target = 'segment1(10-30cm)'\n",
    "data_for_modeling = df[df.index < '2022-08-21']\n",
    "future_df = df[df.index >= '2022-08-21']\n",
    "future_exog = future_df.drop(columns=target)\n",
    "# init environment\n",
    "exp.setup(data = df.reset_index(),\n",
    "          target= target,\n",
    "          seasonal_period=365,\n",
    "          #fold_strategy = 'rolling',\n",
    "          \n",
    "          fig_kwargs=global_plot_settings,\n",
    "          log_experiment=True,\n",
    "          session_id=142)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.plot_model(plot=\"cv\")\n",
    "# Additional plots provided by PyCaret to help understand what is being done.\n",
    "#plot_model(cv, plot=\"train_test_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and selection\n",
    "print(\"Model training and selection\")\n",
    "best_model = exp.compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(best_model,\n",
    "               plot = 'forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics plot\n",
    "exp.plot_model(plot = 'diagnostics')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#snaive= exp.create_model(\"snaive\")\n",
    "\n",
    "#forecast in unknown future\n",
    "exp.plot_model(snaive,\n",
    "               plot = 'forecast',\n",
    "               data_kwargs = {'fh' :1000})\n",
    "\n",
    "Naive_Forecaster= exp.create_model(\"naive\")\n",
    "\n",
    "#forecast in unknown future\n",
    "exp.plot_model(Naive_Forecaster,\n",
    "               plot = 'forecast',\n",
    "               data_kwargs = {'fh' :1000})\n",
    "\n",
    "Grand_means_Forecaster= exp.create_model(\"grand_means\")\n",
    "\n",
    "#forecast in unknown future\n",
    "exp.plot_model(Grand_means_Forecaster,\n",
    "               plot = 'forecast',\n",
    "               data_kwargs = {'fh' :1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned= exp.tune_model(best_model,fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast in unknown future\n",
    "exp.plot_model(tuned,\n",
    "               plot = 'forecast',\n",
    "               data_kwargs = {'fh' : 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition plot\n",
    "exp.plot_model(tuned, plot = 'residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics plot\n",
    "exp.plot_model(tuned, plot = 'diagnostics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize model\n",
    "final_best = exp.finalize_model(tuned)\n",
    "print(final_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "preds= exp.predict_model(final_best,fh=2000,X=future_exog)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "exp.save_model(final_best, 'my_best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# in-sample plot\n",
    "exp.plot_model(tuned, plot = 'insample')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# diagnostics plot\n",
    "exp.plot_model(tuned, plot = 'diagnostics')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prediction = exp.predict_model(best_model)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We will work on in-sample residuals that are provided by PyCaret automatically\n",
    "# But if you need out of sample residuals, you can get them like this.\n",
    "xresiduals = exp.get_config(\"y_test\") - prediction\n",
    "xresiduals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-V4riHCUZj5R",
    "tags": []
   },
   "source": [
    "Feature Selection\n",
    "## __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "ohMOUQgcO9Q6",
    "outputId": "0b4919b6-339e-4ad2-9f5a-45ab5475c155"
   },
   "outputs": [],
   "source": [
    "#Building and displaying Correlation Matrix\n",
    "corrMatrix = df.corr()\n",
    "#print(corrMatrix)\n",
    "\n",
    "_,ax=plt.subplots(1,1,figsize=(20,20))\n",
    "sn.heatmap(df.corr(),annot=True, ax=ax,fmt='.2g', cbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "SHXaTI2IY6_l",
    "outputId": "d7f4fedd-fcd7-4802-8ddc-1e6c20c40865"
   },
   "outputs": [],
   "source": [
    "x = df.corr()\n",
    "highly_corr = {}\n",
    "for columns in x.columns:\n",
    "  highly_corr[columns] = list(x[columns][x[columns]> 0.6].index)\n",
    "#print(x['Air Pressure (x10)'][x['Air Pressure (x10)']> 0.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fa2ydgV1bBIf",
    "outputId": "6a9f5093-2dc0-46b7-d6b7-978869dd0da5"
   },
   "outputs": [],
   "source": [
    "highly_corr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNULlAGvPCcp",
    "outputId": "3ac25e60-29e8-4fa3-a7e2-9f2707caf779"
   },
   "source": [
    "# get histogram to see if the data conforms to Gaussian ( it has bell distribution curve)\n",
    "df.hist(figsize=(25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "v4HXkia5PEeE",
    "outputId": "27d5bfb9-f98e-424a-9192-47d01c4ac733"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzc8mamxPHY2"
   },
   "outputs": [],
   "source": [
    "#Variance Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "-zMDtkiMPJAy",
    "outputId": "71e3ba2c-4cb4-4800-ae31-1c79aeb0cbe4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold \n",
    "\n",
    "\n",
    "#dfTreshold = df\n",
    "# we are making a copy of dataframe and assigning to new variable \n",
    "# instead of pointing a new variable through the memory of the old file\n",
    "dfTreshold = df.copy()\n",
    "\n",
    "dfTreshold.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLThTIa1PLKv",
    "outputId": "0302f401-6741-46b7-cd3c-473dd9c5d0c9"
   },
   "outputs": [],
   "source": [
    "VarThresh = VarianceThreshold(threshold = 0.8)\n",
    "VarThresh.fit(dfTreshold)\n",
    "VarThresh.get_support()\n",
    "\n",
    "## All useless columns are False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "9fwEiFxWPTpS",
    "outputId": "67cc7861-e751-4279-8348-2acf4e0c030f"
   },
   "outputs": [],
   "source": [
    "# VIF -\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# VIF dataframe\n",
    "\n",
    "vif_data = df.copy()\n",
    "del vif_data['segment1(10-30cm)']\n",
    "X = df[df.columns]\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "  \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_LZjo25wPWLb",
    "outputId": "132ed0a0-561e-449c-b12a-42e8cffae1cc"
   },
   "outputs": [],
   "source": [
    "## cut off treshhold\n",
    "vif_data.sort_values(by='VIF', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUUq9nRlPYOU",
    "outputId": "78727e68-87f6-461f-a58d-3527e5af9961"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "data = df.copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#del data['DateTime']\n",
    "y = data.iloc[:,9]  #target variable column is segment1(10-30cm)\n",
    "print(y)\n",
    "X = data.drop('segment1(10-30cm)', axis=1) #independent variable columns\n",
    "X\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "RYEpfZaSPdw4"
   },
   "source": [
    " \n",
    "#extracting top 10 best features by applying SelectKBest class\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NnDfB823PgcE"
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normal = pd.DataFrame(scaler.fit_transform(X),columns=X.columns)\n",
    "y=y.astype('int64')\n",
    "#X_normal\n",
    "#fit = bestfeatures.fit(X_normal,y)\n",
    "#dfcolumns = pd.DataFrame(X.columns)\n",
    "#dfscores = pd.DataFrame(fit.scores_)\n",
    "#dfscores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE53KXLsjXdO",
    "outputId": "509fc590-dff9-42a1-de6b-617c0c59218c"
   },
   "source": [
    "#cursive Feature EliminationPython\n",
    "# Recursive Feature Elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model)\n",
    "rfe = rfe.fit(X_normal, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zL0aa-tpmTfq",
    "outputId": "df0d8c03-bab6-4e51-84a2-586ad9de98cc"
   },
   "source": [
    "X.loc[:,rfe.support_].columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lgLzJB_mg6c",
    "outputId": "46c5b076-c66e-4936-aed9-4e4b239cb1be"
   },
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression()).fit(X_normal, y)\n",
    "selector.estimator_.coef_\n",
    "selector.threshold_\n",
    "ss = selector.get_support()\n",
    "X.loc[:,ss_].columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "idM75m5anp_y",
    "outputId": "86b4058e-ffd5-42df-9959-cf826ed4ebfa"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(X_normal, y)\n",
    "importance = np.abs(ridge.coef_)\n",
    "feature_names = np.array(X.columns)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(width=importance, y=feature_names)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "itIjK2QvpNau"
   },
   "source": [
    "f_df = pd.DataFrame(importance,columns=['result'],index=feature_names)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yJhOEoqRpFOx",
    "outputId": "0ec9d625-e21f-4989-fd7d-5c22c6bd70c0"
   },
   "source": [
    "f_df.query('result>=0.3').plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMwPkT43qf8S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37ba9b67d9923583f6a52e09830e5a986fcf3eeb2107ed50c2100bb59860102b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
